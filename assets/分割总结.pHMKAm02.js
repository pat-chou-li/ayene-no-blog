import{_ as h}from"./ValaxyMain.vue_vue_type_style_index_0_lang.on4_726D.js";import"./chunks/@vueuse/motion.Bf6_DV_X.js";import{_ as g,a as d,b as v}from"./image-20240625145025412.B8WzKMug.js";import{e as y,u as x,a as k}from"./chunks/vue-router.CDV2LZ_i.js";import{aa as A,aq as l,ag as e,af as a,ai as s,F as f,ab as b,Z as M}from"./framework.DmXNyegR.js";import"./app.CZR6THSy.js";import"./chunks/dayjs.BdcnXKr1.js";import"./chunks/vue-i18n.DfFCechf.js";import"./chunks/pinia.DvPpdoxl.js";/* empty css                    */import"./chunks/nprogress.Bru8d7fl.js";import"./YunComment.vue_vue_type_style_index_0_lang.BaUdOGFx.js";import"./index.C5okkQwF.js";import"./YunPageHeader.vue_vue_type_script_setup_true_lang.D2Q9Gv0h.js";import"./post.CDDobuH6.js";const S="/ayene-no-blog/assets/image-20240629171604549.CMZMtF8l.png",w="/ayene-no-blog/assets/image-20240629181028547.BQDJT2nV.png",D="data:image/png;base64,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",G="/ayene-no-blog/assets/image-20240629184157897.DeMKX8ew.png",z=y("/posts/分割总结",async t=>JSON.parse('{"title":"分割总结","description":"","frontmatter":{"title":"分割总结","date":"2024.6.20","categories":"阅读笔记","tags":["图形学","NeRF","3DGS","3D分割"]},"headers":[],"relativePath":"pages/posts/分割总结.md","lastUpdated":1764579964000}'),{lazy:(t,i)=>t.name===i.name}),H={__name:"分割总结",setup(t,{expose:i}){const{data:r}=z(),p=k(),u=x(),m=Object.assign(u.meta.frontmatter||{},r.value?.frontmatter||{});return p.currentRoute.value.data=r.value,M("valaxy:frontmatter",m),globalThis.$frontmatter=m,i({frontmatter:{title:"分割总结",date:"2024.6.20",categories:"阅读笔记",tags:["图形学","NeRF","3DGS","3D分割"]}}),(n,o)=>{const c=h;return b(),A(c,{frontmatter:f(m)},{"main-content-md":l(()=>[...o[0]||(o[0]=[a("h2",{id:"直接蒸馏已有特征",tabindex:"-1"},[s("直接蒸馏已有特征 "),a("a",{class:"header-anchor",href:"#直接蒸馏已有特征","aria-label":'Permalink to "直接蒸馏已有特征"'},"​")],-1),a("p",null,[s("为表统一，所有附加在GS上的特征，再通过阿尔法合成得到的特征图统一定义为"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"F")]),a("annotation",{encoding:"application/x-tex"},"F")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.6833em"}}),a("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"F")])])]),s("​")],-1),a("h3",{id:"如何提取pixel-level的特征",tabindex:"-1"},[s("如何提取pixel-level的特征？ "),a("a",{class:"header-anchor",href:"#如何提取pixel-level的特征","aria-label":'Permalink to "如何提取pixel-level的特征？"'},"​")],-1),a("p",null,"CLIP的特征是image-level的粗糙特征，但需要的是pixel-level的特征，才能直接对3DGS的渲染图像优化。",-1),a("ul",null,[a("li",null,[a("p",null,"Feature Splatting："),a("ul",null,[a("li",null,[s("将CLIP特征用SAM mask平均池化，再分配到每个像素上，形成图(d)，直接和"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"F")]),a("annotation",{encoding:"application/x-tex"},"F")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.6833em"}}),a("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"F")])])]),s("做监督")]),a("li",null,"利用DINOv2的像素级特征做辅助")]),a("figure",null,[a("img",{src:S,alt:"image-20240629171604549",loading:"lazy",decoding:"async"})])]),a("li",null,[a("p",null,"Segment Any 3D Gaussians："),a("ul",null,[a("li",null,"将SAM特征用SAM mask平均池化成一个特征向量，不按像素分配回特征图，而是作为一个query"),a("li",null,[s("将该query分别与"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"F")]),a("annotation",{encoding:"application/x-tex"},"F")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.6833em"}}),a("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"F")])])]),s("中所有像素做余弦相似度查询，得到一个可能性图，将可能性图与SAM做监督")]),a("li",null,[s("举个例子，图像中有一个椅子的mask，使用该mask得到椅子的SAM特征，再依次问"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"F")]),a("annotation",{encoding:"application/x-tex"},"F")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.6833em"}}),a("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"F")])])]),s("​的每一个像素，你是否是一个椅子？然后给出可能性图，和椅子的mask做监督")])])]),a("li",null,[a("p",null,"LangSplat："),a("ul",null,[a("li",null,"把图片过了SAM之后再送进CLIP得到特征，分配给pixel作为pixel-level的特征")]),a("figure",null,[a("img",{src:w,alt:"image-20240629181028547",loading:"lazy",decoding:"async"})])])],-1),a("h3",{id:"如何解决速度和内存问题",tabindex:"-1"},[s("如何解决速度和内存问题？ "),a("a",{class:"header-anchor",href:"#如何解决速度和内存问题","aria-label":'Permalink to "如何解决速度和内存问题？"'},"​")],-1),a("ul",null,[a("li",null,[a("p",null,"Feature Splatting：直接光栅化高维度特征会导致昂贵的训练时间，深入分析后发现主要瓶颈在内存访问模式，通过设计了cuda kernal解决")]),a("li",null,[a("p",null,"SegAnyGaussian：在最开始就使用MLP对SAM特征进行降维，蒸馏特征时一起训练"),a("figure",null,[a("img",{src:D,alt:"image-20240629181348308",loading:"lazy",decoding:"async"})])]),a("li",null,[a("p",null,"LangSplat：开始训练3DGS前，先训练一个MLP构成的编码-解码器，于是用降维的特征蒸馏，再用升维的特征查询")]),a("li",null,[a("p",null,"Feature 3DGS：直接用不需要训练的卷积，GS嵌入低维特征，上采样回高维和CLIP特征做监督")])],-1),a("h3",{id:"如何查询",tabindex:"-1"},[s("如何查询 "),a("a",{class:"header-anchor",href:"#如何查询","aria-label":'Permalink to "如何查询"'},"​")],-1),a("p",null,"将CLIP特征蒸馏到每个3DGS后，如何选中需要的高斯？",-1),a("figure",null,[a("img",{src:G,alt:"image-20240629184157897",loading:"lazy",decoding:"async"})],-1),a("ul",null,[a("li",null,"Feature Splatting: 将text通过clip text encoder得到词汇的text embeddings，计算与每个GS的相似度"),a("li",null,"SegAny3DGS：user选取图片中的第一个点，送给SAM得到对应物体的mask，得到平均池化SAM特征作为Query，依次查询每个高斯")],-1),a("h2",{id:"利用sam训练出场景特化的特征",tabindex:"-1"},[s("利用SAM训练出场景特化的特征 "),a("a",{class:"header-anchor",href:"#利用sam训练出场景特化的特征","aria-label":'Permalink to "利用SAM训练出场景特化的特征"'},"​")],-1),a("h3",{id:"怎么利用sam设计loss完成无监督训练",tabindex:"-1"},[s("怎么利用SAM设计loss完成无监督训练？ "),a("a",{class:"header-anchor",href:"#怎么利用sam设计loss完成无监督训练","aria-label":'Permalink to "怎么利用SAM设计loss完成无监督训练？"'},"​")],-1),a("p",null,"现在没有一个直接的目标：即上一个方法的将CLIP或SAM特征蒸馏到高斯上，而是要训练出一个属于自己场景的特征，大体上有两个思路",-1),a("h4",{id:"先得到场景中到底有几类物体-从而转化为分类问题",tabindex:"-1"},[s("先得到场景中到底有几类物体，从而转化为分类问题 "),a("a",{class:"header-anchor",href:"#先得到场景中到底有几类物体-从而转化为分类问题","aria-label":'Permalink to "先得到场景中到底有几类物体，从而转化为分类问题"'},"​")],-1),a("ul",null,[a("li",null,"Gaussian Grouping：采用视频跟踪模型，将多视角图片视为视频序列，得到不同视角下的mask之间的联系，从而得到一组图片中到底有几类物体"),a("li",null,[s("Group Any Gaussians： "),a("ul",null,[a("li",null,"对于任一mask，根据相机内参反投影到相机空间，选取前x%的高斯，认为这些高斯就是这个mask代表的高斯"),a("li",null,"根据每个mask对应的高斯的交并比，将mask进行分类，从而得到整个场景到底有几类物体")])])],-1),a("h4",{id:"相同mask下的高斯有近似的特征-不同的mask下的高斯具有远离的特征就可以了",tabindex:"-1"},[s("相同mask下的高斯有近似的特征，不同的mask下的高斯具有远离的特征就可以了 "),a("a",{class:"header-anchor",href:"#相同mask下的高斯有近似的特征-不同的mask下的高斯具有远离的特征就可以了","aria-label":'Permalink to "相同mask下的高斯有近似的特征，不同的mask下的高斯具有远离的特征就可以了"'},"​")],-1),a("ul",null,[a("li",null,[a("p",null,"OpenGaussian："),a("p",null,"提出掩码内平滑损失和掩码间对比损失，"),a("p",null,"intra-mask smoothing loss：掩码内平滑损失"),a("figure",null,[a("img",{src:g,alt:"image-20240624145935712",loading:"lazy",decoding:"async"})]),a("p",null,[s("先阿尔法合成渲染出一张特征图M，然后用SAM得到m个实例的平均池化特征，再以每个实例中的每个像素点和平均特征做一致性损失，即"),a("strong",null,"约束mask内的每个像素具有相同的特征")]),a("p",null,"inter-mask contrastive loss：掩码间对比损失："),a("figure",null,[a("img",{src:d,alt:"image-20240624150757369",loading:"lazy",decoding:"async"})]),a("p",null,"总之不同instance的特征越接近，损失越大。")])],-1),a("h2",{id:"一些正则项",tabindex:"-1"},[s("一些正则项 "),a("a",{class:"header-anchor",href:"#一些正则项","aria-label":'Permalink to "一些正则项"'},"​")],-1),a("ul",null,[a("li",null,[a("p",null,"Segment Any 3DGS ： Correspondence Loss，让共享更多mask的两个像素拥有相近的特征")]),a("li",null,[a("p",null,[s("Gaussian Grouping ：3D正则化损失（空间），用P表示一个3DGS的身份编码"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("msub",null,[a("mi",null,"e"),a("mi",null,"i")])]),a("annotation",{encoding:"application/x-tex"},"e_i")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"e"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t vlist-t2"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.3117em"}},[a("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mathnormal mtight"},"i")])])]),a("span",{class:"vlist-s"},"​")]),a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.15em"}},[a("span")])])])])])])])]),s(",Q表示该3DGS的最近k个GS的身份编码集合"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("msub",null,[a("mi",null,"e"),a("mn",null,"1")]),a("mo",{separator:"true"},","),a("msub",null,[a("mi",null,"e"),a("mn",null,"2")]),a("mi",{mathvariant:"normal"},"."),a("mi",{mathvariant:"normal"},"."),a("mi",{mathvariant:"normal"},"."),a("mo",{separator:"true"},","),a("msub",null,[a("mi",null,"e"),a("mi",null,"k")])]),a("annotation",{encoding:"application/x-tex"},"{e_1,e_2...,e_k}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),a("span",{class:"mord"},[a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"e"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t vlist-t2"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.3011em"}},[a("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},"1")])])]),a("span",{class:"vlist-s"},"​")]),a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.15em"}},[a("span")])])])])]),a("span",{class:"mpunct"},","),a("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"e"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t vlist-t2"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.3011em"}},[a("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},"2")])])]),a("span",{class:"vlist-s"},"​")]),a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.15em"}},[a("span")])])])])]),a("span",{class:"mord"},"..."),a("span",{class:"mpunct"},","),a("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"e"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t vlist-t2"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.3361em"}},[a("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])]),a("span",{class:"vlist-s"},"​")]),a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.15em"}},[a("span")])])])])])])])])]),s(",用KL散度衡量P和Q身份编码的差异，即约束最近的身份编码要尽量相同")]),a("figure",null,[a("img",{src:v,alt:"image-20240625145025412",loading:"lazy",decoding:"async"})])])],-1),a("h2",{id:"总结",tabindex:"-1"},[s("总结 "),a("a",{class:"header-anchor",href:"#总结","aria-label":'Permalink to "总结"'},"​")],-1),a("p",null,"3DGS从出现到流行不到一年，由于显式表示和隐式表示的巨大差异，语义嵌入上并不能简单的从NeRF迁移到3DGS，因此现阶段仍处于解决将语义嵌入GS中遇到的种种问题的一个阶段，还没有到设计各种复杂的模型和机制卷精度的时候，体现在：",-1),a("ul",null,[a("li",null,"对于直接蒸馏的方法，大多论文创新点集中在如何解决高维嵌入的内存和速度问题、如何获得pixel-level的特征配合GS的光栅化框架蒸馏的问题，这些是使用蒸馏这一方法天然会遇到的，因此大家的论文看起来有些重复"),a("li",null,"对于无监督的方法，大多论文集中在如何让这个方法跑起来的阶段，转化为分类问题是一个思路，还有其他的吗")],-1),a("p",null,"也因此，对于种种下游任务专门做设计的论文也还没有出现，比如我们要求具体到GS操纵的需求，而不单单是多视角一致性分割的需求，其实应该是具身智能等任务的一个应用条件。应该思考如何为我们的场景定制一个pipeline，比如以下几点",-1),a("ul",null,[a("li",null,"能不能不用相似性查询，如果一个高斯被彻底的分类会不会好一点？因为相似性查询可能会有歧义，人工设定的阈值很难界定，会导致多分割或少分割。"),a("li",null,"设计pipeline时，应充分考虑我们是已经有3DGS建模好的场景的，同一物体GS相邻的先验能不能利用？颜色相近能不能利用？"),a("li",null,"对于细节，可不可以在点云分割领域寻找一些可用的后处理手段？")],-1)])]),"main-header":l(()=>[e(n.$slots,"main-header")]),"main-header-after":l(()=>[e(n.$slots,"main-header-after")]),"main-nav":l(()=>[e(n.$slots,"main-nav")]),"main-content-before":l(()=>[e(n.$slots,"main-content-before")]),"main-content":l(()=>[e(n.$slots,"main-content")]),"main-content-after":l(()=>[e(n.$slots,"main-content-after")]),"main-nav-before":l(()=>[e(n.$slots,"main-nav-before")]),"main-nav-after":l(()=>[e(n.$slots,"main-nav-after")]),comment:l(()=>[e(n.$slots,"comment")]),footer:l(()=>[e(n.$slots,"footer")]),aside:l(()=>[e(n.$slots,"aside")]),"aside-custom":l(()=>[e(n.$slots,"aside-custom")]),default:l(()=>[e(n.$slots,"default")]),_:3},8,["frontmatter"])}}};export{H as default,z as usePageData};
