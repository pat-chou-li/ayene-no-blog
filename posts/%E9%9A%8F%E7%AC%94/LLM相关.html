<!DOCTYPE html><html lang="en" data-beasties-container><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" href="/favicon.svg"><script>!function(){const e=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,t=localStorage.getItem("vueuse-color-scheme")||"auto";("dark"===t||e&&"light"!==t)&&document.documentElement.classList.toggle("dark",!0)}()</script><style type="text/css">:root{color-scheme:light dark;--va-c-bg:#fff}html{background-color:var(--va-c-bg)}</style><script>const locale=localStorage.getItem("valaxy-locale")||"zh-CN";document.documentElement.setAttribute("lang",locale)</script><script type="module" async crossorigin src="/ayene-no-blog/assets/app.5Pc5wqE0.js"></script><link rel="modulepreload" crossorigin href="/ayene-no-blog/assets/framework.BWK1Zvdg.js"><link rel="modulepreload" crossorigin href="/ayene-no-blog/assets/chunks/@vueuse/motion.CDGXpttC.js"><link rel="modulepreload" crossorigin href="/ayene-no-blog/assets/chunks/vue-router.DlUPz4t8.js"><link rel="modulepreload" crossorigin href="/ayene-no-blog/assets/chunks/dayjs.BldX5ftQ.js"><link rel="modulepreload" crossorigin href="/ayene-no-blog/assets/chunks/vue-i18n.lF0SUo7_.js"><link rel="modulepreload" crossorigin href="/ayene-no-blog/assets/chunks/pinia.BYsrTFz1.js"><link rel="modulepreload" crossorigin href="/ayene-no-blog/assets/chunks/nprogress.DxEoPAls.js"><link rel="stylesheet" crossorigin href="/ayene-no-blog/assets/app.B3NQSKti.css"><link rel="stylesheet" crossorigin href="/ayene-no-blog/assets/group-icons.CNuSYZDE.css"><link rel="modulepreload" crossorigin href="/ayene-no-blog/assets/post.BIZmRJsi.js"><link rel="stylesheet" href="/ayene-no-blog/assets/group-icons.CNuSYZDE.css"><link rel="modulepreload" crossorigin href="/ayene-no-blog/assets/LLM相关.BcIwsdia.js"><title>LLM相关 - ayane no blog</title><script id="check-mac-os" async>document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap"><meta property="og:locale:alternate" content="en"><meta name="description" content="我从来没有觉得学图形学开心过。"><meta property="og:description" content="我从来没有觉得学图形学开心过。"><meta property="og:locale" content="zh-CN"><meta property="og:site_name" content="ayane no blog"><meta property="og:title" content="LLM相关"><meta property="og:image" content="/favicon.svg"><meta property="og:type" content="website"><meta property="og:url" content="https://pat-chou-li.github.io/ayene-no-blog/"><link rel="icon" href="/favicon.svg" type="image/svg+xml"><meta name="generator" content="Valaxy 0.26.3"><meta name="theme-color" content="#fff"><meta name="msapplication-TileColor" content="#fff"><meta name="twitter:card" content="summary_large_image"></head><body><div id="app" data-server-rendered="true"><!--[--><!--[--><!--[--><!----><!----><div class="yun-page-header-gradient" style="--gradient-from:161 196 253;--gradient-to:194 233 251"></div><!----><!----><!----><canvas class="fireworks"></canvas><!--[--><div class="yun-bg"></div><!--]--><div class="yun-page-loading" absolute left-0 right-0 bottom-0 top-0 flex justify="center" items-center z-10 bg="$va-c-bg" data-v-673bc094><div class="spinner" data-v-673bc094></div></div><a href="#" class="back-to-top yun-icon-btn bg-$va-c-bg-soft shadow-md"><div class="size-8" i-ri-arrow-up-s-line></div><svg class="progress-circle-container" viewBox="0 0 100 100"><circle stroke-dasharray="301.59289474462014 301.59289474462014" stroke-dashoffset="301.59289474462014" stroke="currentColor" stroke-width="2" stroke-linecap="round" class="progress-circle" cx="50" cy="50" r="48" fill="none"/></svg></a><!-- TODO --><!-- <YunDock /> --><!--]--><!--[--><!--]--><!----><!--]--><!--[--><div flex="~" class="w-full m-auto justify-center items-start gap-4 mt-12 md:mt-24"><!--[--><!----><main class="yun-main lt-md:w-full" flex="~ center"><!--[--><div class="content w-full md:w-3xl lg:w-2xl xl:w-2xl 2xl:w-4xl" flex="~ col grow" p="lt-md:0"><div class="yun-card flex-center rounded-2 relative" flex="col" min-h="100px" bg="$va-c-bg-light" m="0" style><!----><!----><!--[--><div class="mt-8 mb-4"><!--[--><header class="post-header"><h1 p="2" text="2xl center" font="serif black" style="" class="post-title flex-center"><!----><span inline-flex class="leading-none">LLM相关</span></h1></header><!--]--></div><!--[--><!--[--><!--[--><!--[--><!----><!----><!----><div flex="~ center" text="sm" class="flex-col gap-2! post-meta gap-4"><div class="post-time flex items-center gap-4"><span class="posted-time inline-flex-center gap-1" title="发表于2025-07-20 00:00:00"><div class="inline-block" i-ri-calendar-line></div><time class="op-80">2025-07-20</time></span><span class="edited-time inline-flex-center gap-1" title="更新于2025-08-22 09:02:38"><div i-ri-calendar-2-line></div><time class="op-80">2025-08-22</time></span></div><!--[--><!--]--><div class="inline-flex-center gap-4"><!----><!----></div></div><!--]--><div class="inline-flex mt-2" text="sm" py="1"><a href="/ayene-no-blog/categories?category=LLM" class="transition post-category inline-flex-center text-xs border-$va-c-divider" px-2 h="7" border rounded-full hover="bg-blue-500 text-white"><div m="x-1" inline-flex i-ri-folder-2-line></div><span>LLM</span></a><span mx="2"></span><div class="post-tags inline-flex" items="center" gap="1" flex="wrap 1" justify="end"><!--[--><a href="/ayene-no-blog/tags/?tag=LLM" class="transition post-tag inline-flex-center text-xs border-$va-c-divider" px-2 h="7" rounded-full border hover="bg-blue-500 text-white"><span>LLM</span></a><!--]--></div></div><!--]--><!--]--><!--]--><div p="x-4 b-8" class="sm:px-6 lg:px-12 xl:px-16" w="full"><!--[--><!--]--><!--[--><!-- <Transition appear> --><article class="markdown-body"><!--[--><!----><!----><!--[--><!--]--><!--[--><h2 id="一-llm训练流程" tabindex="-1">一. LLM训练流程 <a class="header-anchor" href="#一-llm训练流程" aria-label="Permalink to &quot;一. LLM训练流程&quot;">​</a></h2><figure><img src="/ayene-no-blog/assets/2-0.B-kP4mJM.jpg" alt="alt text" loading="lazy" decoding="async"></figure><p>训练出LLM一般需要经过Pretrain、SFT、RLHF三个阶段。</p><p>pretrain</p><p>sft</p><p>rlhf</p><h3 id="pretrain" tabindex="-1">pretrain <a class="header-anchor" href="#pretrain" aria-label="Permalink to &quot;pretrain&quot;">​</a></h3><ul><li>模型架构：各类基于transformer的decoder-only架构</li><li>任务制定：CLM为主</li><li>计算需求：分布式训练方法</li><li>数据需求：互联网上的海量文本</li></ul><h4 id="任务制定" tabindex="-1">任务制定 <a class="header-anchor" href="#任务制定" aria-label="Permalink to &quot;任务制定&quot;">​</a></h4><p>pretrain的数据集自然是互联网上的海量文本，但是既然要训练，自然需要一个任务，并且根据这项任务对数据进行处理，现在最常用的方法是CLM（Causal Language Model，因果语言模型）。</p><p>CLM：根据前面所有的token来预测下一个token。（现在的主流，Lamma，gpt，qwen等）</p><div class="language-tex"><button title="Copy code" class="copy"></button><span class="lang">tex</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code v-pre><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">input: 今天天气</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">output: 今天天气很</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">input: 今天天气很</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">output：今天天气很好</span></span></code></pre><button class="code-block-unfold-btn"></button></div><p>在实践上，在计算transformer的时候通过掩码注意力机制，将后续的注意力权重调整为0，使得每个token只能关注前面的token。（即在训练时对模型加mask，并不是对输入加mask使得文本不可见）</p><div class="language-mark"><button title="Copy code" class="copy"></button><span class="lang">mark</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code v-pre><span class="line"><span> 【MASK】【MASK】【MASK】【MASK】</span></span>
<span class="line"><span>    I   【MASK】 【MASK】【MASK】</span></span>
<span class="line"><span>    I     like  【MASK】【MASK】</span></span>
<span class="line"><span>    I     like    you  【MASK】</span></span>
<span class="line"><span>    I     like    you   .</span></span></code></pre><button class="code-block-unfold-btn"></button></div><p>其他并不主流的方式，但仍然存在</p><p>MLM：随机屏蔽部分token，让模型完成类似完形填空的任务。</p><div class="language-markdown"><button title="Copy code" class="copy"></button><span class="lang">markdown</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code v-pre><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">输入：I &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">MASK</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">&gt; you because you are &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">MASK</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">输出：&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">MASK</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">&gt; - love; &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">MASK</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">&gt; - wonderful</span></span></code></pre><button class="code-block-unfold-btn"></button></div><p>NSP：输入两个句子，判断是否构成上下文。</p><h4 id="计算需求" tabindex="-1">计算需求 <a class="header-anchor" href="#计算需求" aria-label="Permalink to &quot;计算需求&quot;">​</a></h4><p>大模型的显存开销显然是单张GPU无法接受的，在实践中，需要将模型参数、模型梯度、Adam状态参数等等进行分片，例如可以将两个batch放到两张gpu上，然后通过通信共享梯度，完成类似batch_size的并行训练，被称为<strong>Data Parallelism（数据并行）</strong>：</p><img src="/ayene-no-blog/assets/2-1.C_UGwZOT.jpg" alt="alt text" style="zoom:67%"><p>例如将模型参数本身放到不同的GPU上：</p><img src="/ayene-no-blog/assets/2-2.BaGuuOEh.jpg" alt="alt text" style="zoom:50%"><p>显而易见的，越是高的分片，带来越高的通信开销，因此哪些内容适合分片，哪些内容适合所有GPU上对齐。</p><p>除了分片以外，还有很多手段降低显存开销</p><ul><li>CPU-offline：将部分计算、缓存转移至CPU</li><li>算子优化：针对Transformer优化矩阵乘法等算子，减少中间矩阵，降低显存开销</li><li>量化、压缩：例如对梯度进行压缩后再通信，以梯度精度损失为代价降低通信</li><li>…</li></ul><h4 id="数据需求" tabindex="-1">数据需求 <a class="header-anchor" href="#数据需求" aria-label="Permalink to &quot;数据需求&quot;">​</a></h4><p>如何从互联网中获取高质量语料用于训练？（tips：目前各公司并不完全开源其高质量语料库）</p><ul><li>文档准备：通过爬虫、简单的URL过滤、语种过滤等，收集大量文本数据。</li><li>语料过滤：去除低质量、无意义、有害内容，如乱码广告等，方法包括：<ul><li>通过高质量语料库训练一个文本分类器</li><li>人工标定</li></ul></li><li>语料去重：hash计算相似性、模式匹配等</li></ul><h3 id="sft-监督微调" tabindex="-1">SFT（监督微调） <a class="header-anchor" href="#sft-监督微调" aria-label="Permalink to &quot;SFT（监督微调）&quot;">​</a></h3><h4 id="指令微调" tabindex="-1">指令微调 <a class="header-anchor" href="#指令微调" aria-label="Permalink to &quot;指令微调&quot;">​</a></h4><p>大模型SFT与传统中对模型续训、微调的方法并不相同。</p><p>传统上，我们想让一个模型能完成特定的下游任务的任务，例如要完成机器翻译，我们就提供机器翻译的数据集，修改模型的输出，然后进行续训。</p><p>但是LLM微调时，为了增强其泛化性，采用的是指令微调的方式，输入是各种指令，输出则是相应的回复，数据集类似于：</p><div class="language-json"><button title="Copy code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code v-pre><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">input : {</span></span>
<span class="line"><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic">	system</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic"> prompt</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">"你是一个helpful assistant"</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">,</span></span>
<span class="line"><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic">    user</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic"> prompt</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">"告诉我今天的天气预报"</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">,</span></span>
<span class="line"><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic">    assistant</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic"> prompt</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">"根据天气预报，今天天气是晴转多云，最高温度26摄氏度，最低温度9摄氏度，昼夜温差大，请注意保暖哦"</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">}</span></span></code></pre><button class="code-block-unfold-btn"></button></div><p>输入的是一条用户指令，大部分时候会在user prompt前拼接一条system prompt，而assistant prompt就是输出，也就是大模型计算损失时的gt。</p><p>以上是单次会话的训练实例，为了让LLM能够执行多轮对话，SFT中也进行多轮对话的训练，其输入输出为：</p><div class="language-markdown"><button title="Copy code" class="copy"></button><span class="lang">markdown</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code v-pre><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> input=&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">prompt_1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">&gt;&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">completion_1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">&gt;&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">prompt_2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">&gt;&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">completion_2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">&gt;&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">prompt_3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">&gt;&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">completion_3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> output=[</span><span style="--shiki-light:#032F62;--shiki-light-text-decoration:underline;--shiki-dark:#DBEDFF;--shiki-dark-text-decoration:underline">MASK</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">]&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">completion_1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">&gt;[</span><span style="--shiki-light:#032F62;--shiki-light-text-decoration:underline;--shiki-dark:#DBEDFF;--shiki-dark-text-decoration:underline">MASK</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">]&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">completion_2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">&gt;[</span><span style="--shiki-light:#032F62;--shiki-light-text-decoration:underline;--shiki-dark:#DBEDFF;--shiki-dark-text-decoration:underline">MASK</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">]&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">completion_3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> [</span><span style="--shiki-light:#032F62;--shiki-light-text-decoration:underline;--shiki-dark:#DBEDFF;--shiki-dark-text-decoration:underline">MASK</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">]是指不参与loss计算的部分</span></span></code></pre><button class="code-block-unfold-btn"></button></div><h4 id="高效微调" tabindex="-1">高效微调 <a class="header-anchor" href="#高效微调" aria-label="Permalink to &quot;高效微调&quot;">​</a></h4><p>其实可以发现，前面的pretrain和指令微调，都可以理解为正在训练大模型的通用能力，指令微调也需要极高的训练成本，到端侧部署应用时，通常使用的是高效微调方案。</p><h5 id="adapter-tuning" tabindex="-1">Adapter Tuning <a class="header-anchor" href="#adapter-tuning" aria-label="Permalink to &quot;Adapter Tuning&quot;">​</a></h5><figure><img src="/ayene-no-blog/assets/3-1.B2OYP1ye.png" alt="alt text" loading="lazy" decoding="async"></figure><p>在transformer层之间插入一个小型adapter，冻结原有参数，仅训练这些参数。Feedforwarddown-project会将输入维度大幅降低，并在输出时还原。</p><h5 id="lora" tabindex="-1">Lora <a class="header-anchor" href="#lora" aria-label="Permalink to &quot;Lora&quot;">​</a></h5><p>原文：<a href="https://arxiv.org/pdf/2106.09685" target="_blank" rel="noreferrer">https://arxiv.org/pdf/2106.09685</a></p><figure><img src="/ayene-no-blog/assets/image-20250720224305641.BY_JyZU4.png" alt="image-20250720224305641" loading="lazy" decoding="async"></figure><figure><img src="/ayene-no-blog/assets/image-20250720224441025.IsENbXzA.png" alt="image-20250720224441025" loading="lazy" decoding="async"></figure><p>如果仅有左侧的模型，就是全量微调。</p><p>现在将左侧模型冻结，梯度传导到右侧的A和B矩阵。这里解释一下A和B是什么。</p><p>理论上原始参数的梯度是一个较大的矩阵∆W，现在将该矩阵分解为r更低的两个矩阵B和A表示，由于B和A的r更小，更新的参数也大量减小了。</p><p>图上AB的值为初始化的值，即A用高斯初始化，B用0初始化。</p><p>可以看出lora也是一种adapter，但是是并行的加入新参数，通过矩阵分解降低参数更新量。</p><h3 id="rlhf" tabindex="-1">RLHF <a class="header-anchor" href="#rlhf" aria-label="Permalink to &quot;RLHF&quot;">​</a></h3><p>（Reinforcement Learning from Human Feedback， 人类反馈强化学习）</p><p>这一步是为了保证回答能够对齐人类的价值观，使得输出更符合人类偏好，分为两个步骤，训练RM和PPO训练</p><p>RM（Reward Model）</p><p>这一步在训练一个奖励模型，定量评判模型输出的回答在人类看来是否质量不错，即</p><p>输入：【prompt，模型的回答】</p><p>输出：评分（符合人类偏好的程度）</p><p>训练RW的数据则来自于：对于同一个prompt，由LLM不断生成不同的回答，然后人工对这些回答的偏好进行<strong>排序</strong>。</p><hr><p>将RW训练好之后，以RW的评分为标准，不断对LLM进行人类偏好的训练，常用的方式是PPO训练（Proximal Policy Optimization），一种强化学习方法。</p><h2 id="二、大模型应用" tabindex="-1">二、大模型应用 <a class="header-anchor" href="#二、大模型应用" aria-label="Permalink to &quot;二、大模型应用&quot;">​</a></h2><h3 id="rag" tabindex="-1">RAG <a class="header-anchor" href="#rag" aria-label="Permalink to &quot;RAG&quot;">​</a></h3><p>（检索增强生成，Retrieve Augment Generation）</p><p>如果询问LLM专业领域的知识/需要时效性的知识，LLM经常会产生幻觉，捏造文献和一些知识，一种常见的方法是检索专业领域的知识，并且将对应的内容随user prompt一起输入给LLM，从而提升内容的准确性。</p><figure><img src="/ayene-no-blog/assets/jumpstart-fm-rag.DJ7Uanfr.jpg" alt="img" loading="lazy" decoding="async"></figure><ul><li>构建知识库：收集文档，将其chunking，即按一种策略将文档分块，将每块文本embedding成向量，存进向量数据库（以向量为index的数据库，支持相似性搜索）中。</li><li>检索：在输入prompt后，根据prompt从向量DB中检索top-k个context，和prompt拼接后再让LLM生成回答</li></ul><h3 id="agent" tabindex="-1">Agent <a class="header-anchor" href="#agent" aria-label="Permalink to &quot;Agent&quot;">​</a></h3><p>Agent，即在LLM问答推理能力的基础上，增加规划（例如评估任务难度，选择工具函数，分解任务目标…）、记忆（保留历史上下文）和使用工具函数的能力。</p><figure><img src="/ayene-no-blog/assets/7-3-Agent_E5_B7_A5_E4_BD_9C_E5_8E_9F_E7_90_86.BATTr5fI.jpeg" alt="alt text" loading="lazy" decoding="async"></figure><p>上述规划能力，来源可能是prompt工程（比如要求大模型分解任务），可能来源于SFT（标注子任务数据集）</p><p>例如，一种方法叫做few-shot CoT，提供给大模型一个示例，再让其分解对应领域的问题，就可以有比较好的效果</p><div class="language-markdown"><button title="Copy code" class="copy"></button><span class="lang">markdown</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code v-pre><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">问题：罗杰有5个网球，他又买了两盒网球，每盒有3个。他现在总共有多少个网球？</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">思维链：</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">罗杰一开始有5个网球；  </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">购买了两盒，每盒3个，共买了2×3=6个网球；  </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">因此总数是5（原有） + 6（新购） = 11个网球。  </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">答案是11。  </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">请根据以上思考方法，解决下述问题：</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">艾米需要4分钟爬到滑梯顶部，滑下需1分钟。滑梯开放15分钟，她能滑多少次？</span></span></code></pre><button class="code-block-unfold-btn"></button></div><p>规划完成后，LLM会主动调用某些函数，函数调用的能力，则来自于人类自行部署微服务到云端 \ 本体定义函数，通过mcp协议或直接通信，让LLM输出符合函数输入格式的参数，调用函数并返回，再添加到LLM后续输出中。</p><!--]--><!--]--><!----><!----></article><!-- </Transition> --><!--]--><!--[--><!--[--><!--[--><!----><ul class="post-copyright" m="y-4"><li class="post-copyright-author"><strong>本文作者：</strong><span>水沢绫音</span></li><li class="post-copyright-link"><strong>本文链接：</strong><a href="https://pat-chou-li.github.io/ayene-no-blog/posts/%E9%9A%8F%E7%AC%94/LLM相关" target="_blank" title="本文链接">https://pat-chou-li.github.io/ayene-no-blog/posts/随笔/LLM相关</a></li><li class="post-copyright-license"><strong>版权声明：</strong><span>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 ">CC BY-NC-SA</a> 许可协议。</span></li></ul><!--]--><!--]--><!--]--></div><!--]--><!----></div><!--[--><!--]--><!--[--><div class="post-nav"><div class="post-nav-item"><!----></div><div class="post-nav-item"><a href="/ayene-no-blog/posts/%E5%89%8D%E7%AB%AF/周记" class="post-nav-next" title="周记"><span class="title truncate" text="sm">周记</span><div class="icon" i-ri-arrow-right-s-line></div></a></div></div><!--]--><!--[--><!--]--><!----><!--[--><!-- eslint-disable-next-line vue/no-lone-template empty --><template class="mt-4"></template><!--]--><!--[--><!--]--><!--[--><!--]--></div><!--]--></main><!--[--><button class="xl:hidden toc-btn shadow-md fixed yun-icon-btn z-20 bg-$va-c-bg-soft" opacity="75" right="4" bottom="19"><div i-ri-file-list-line></div></button><!----><aside flex="~ col" class="va-card yun-aside sticky top-0 lg:top-$yun-margin-top min-h-sm" text="center" overflow="auto"><div style="display:none" class="w-full" flex="~ col" pb-2><!--[--><h2 m="t-6 b-2" font="serif black">文章目录</h2><div style="display:none" data-v-6dc67c73><div class="content" data-v-6dc67c73><div class="outline-title" data-v-6dc67c73>本页</div><div class="outline-marker" data-v-6dc67c73></div><nav aria-labelledby="doc-outline-aria-label" data-v-6dc67c73><span id="doc-outline-aria-label" class="visually-hidden" data-v-6dc67c73>Table of Contents for current page</span><ul class="root va-toc relative z-1 css-i18n-toc" data-v-6dc67c73 data-v-699db71a><!--[--><!--]--></ul></nav></div></div><!--]--><div class="flex-grow"></div><!----></div></aside><!--]--><!--]--></div><footer flex="~ col" class="relative yun-footer va-footer px-4 py-4 pt-0 text-$va-c-text-light w-full mt-14" bg="white dark:$va-c-bg-soft" text="center sm"><div class="yun-cloud absolute top--10 left-0 right-0"><svg class="waves" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" fill="var(--yun-c-cloud)"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><!----><div class="copyright flex justify-center items-center gap-2" p="1"><span>©<!--[--> 2022 -<!--]--> 2025</span><a class="animate-pulse inline-flex" href="https://www.yunyoujun.cn/sponsors/" target="_blank" title="Sponsor YunYouJun"><div class="i-ri-cloud-line"></div></a><span>水沢绫音</span></div><div class="powered" m="2"><span>由 <a href="git+https://github.com/YunYouJun/valaxy.git" target="_blank" rel="noopener">Valaxy</a> <span class="op-60">v0.26.3</span> 驱动</span><span mx-1>|</span><span><span>主题</span><span mx-1>-</span><a href="git+https://github.com/YunYouJun/valaxy/tree/main/packages/valaxy-theme-yun.git" title="valaxy-theme-yun" target="_blank">Yun</a><span class="ml-1 op-60">v0.26.3</span></span></div><!--[--><!--]--><div class="yun-footer-gradient" style="--gradient-from:161 196 253;--gradient-to:194 233 251"></div></footer><!--]--><!--]--></div><script>window.__INITIAL_STATE__='{"pinia":{"yun-app":{},"app":{"showLoading":true},"site":{},"routerStore":{}}}'</script><script type="application/ld+json" data-hid="schema-org-graph">{"@context":"https://schema.org","@graph":[{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#identity","@type":"Person","name":"水沢绫音","url":"https://pat-chou-li.github.io/ayene-no-blog/","image":{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#/schema/image/658d95f"},"sameAs":["/atom.xml","https://github.com/pat-chou-li","https://www.zhihu.com/people/shui-ze-ling-yin-46","https://space.bilibili.com/8929945?spm_id_from=333.1007.0.0","patchouli13@163.com"]},{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#website","@type":"WebSite","dateModified":"2025-08-22T09:02:38.872Z","datePublished":"2025.07.20","inLanguage":"en","name":"LLM相关","url":"https://pat-chou-li.github.io/ayene-no-blog/","publisher":{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#identity"}},{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#webpage","@type":"WebPage","dateModified":"2025-08-22T09:02:38.872Z","datePublished":"2025-07-20T00:00:00.000Z","description":"我从来没有觉得学图形学开心过。","name":"LLM相关","url":"https://pat-chou-li.github.io/ayene-no-blog/","about":{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#identity"},"isPartOf":{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#website"},"potentialAction":[{"@type":"ReadAction","target":["https://pat-chou-li.github.io/ayene-no-blog/"]}]},{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#article","dateModified":"2025-08-22T09:02:38.872Z","datePublished":"2025-07-20T00:00:00.000Z","description":"我从来没有觉得学图形学开心过。","headline":"LLM相关","inLanguage":"en","thumbnailUrl":"https://pat-chou-li.github.io/ayene-no-blog/favicon.svg","@type":["Article","BlogPosting"],"author":{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#/schema/person/6678b6b"},"image":{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#/schema/image/19d7713"},"isPartOf":{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#webpage"},"mainEntityOfPage":{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#webpage"},"publisher":{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#identity"}},{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#/schema/person/6678b6b","@type":"Person","name":"水沢绫音","url":"https://valaxy.site"},{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#/schema/image/658d95f","@type":"ImageObject","contentUrl":"https://raw.githubusercontent.com/pat-chou-li/ayene-no-blog/main/resource/avatar.jpg","inLanguage":"en","url":"https://raw.githubusercontent.com/pat-chou-li/ayene-no-blog/main/resource/avatar.jpg"},{"@id":"https://pat-chou-li.github.io/ayene-no-blog/#/schema/image/19d7713","@type":"ImageObject","contentUrl":"https://pat-chou-li.github.io/ayene-no-blog/favicon.svg","inLanguage":"en","url":"https://pat-chou-li.github.io/ayene-no-blog/favicon.svg"}]}</script></body></html>